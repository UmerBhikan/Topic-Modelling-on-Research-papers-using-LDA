{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Importing Libraries and reading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path of the folder named train_txt: C:\\Users\\umerb\\IMS\\PROJECTS\\train_txt\n",
      "['data01.txt', 'data02.txt', 'data03.txt', 'data04.txt', 'data05.txt', 'data06.txt', 'data07.txt', 'data08.txt', 'data09.txt', 'data10.txt', 'data11.txt', 'data12.txt', 'data13.txt', 'data14.txt', 'data15.txt', 'data16.txt', 'data17.txt', 'data18.txt', 'data19.txt', 'data20.txt']\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = input(r\"Enter the path of the folder named train_txt: \")\n",
    "print(os.listdir(DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Preprocessing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = [\"data{0:02}\".format(i) for i in range(1,2)]\n",
    "# Read all texts into a list.\n",
    "papers = []\n",
    "for folder in folders:\n",
    "    file_names = os.listdir(DATA_PATH)\n",
    "    for file_name in file_names:\n",
    "        with open(DATA_PATH + '/' + file_name, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
    "            data = f.read()\n",
    "        papers.append(data)\n",
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article\n",
      "\n",
      "Overcoming Barriers in Supply Chain Analytics—\n",
      "Investigating Measures in LSCM Organizations\n",
      "Tino T. Herden *, Benjamin Nitsche and Benno Gerlach\n",
      "Chair of Logistics, Technische Universität Berlin, Straße des 17. Juni 135, 10623 Berlin, Germany\n",
      "* Correspondence: herden@logistik.tu-berlin.de\n",
      "Received: 23 December 2019; Accepted: 17 February 2020; Published: 26 February 2020\n",
      "\n",
      "Abstract: While supply chain analytics shows promise regarding value, benefits, and increase in\n",
      "performance for logistics and supply chain management (LSCM) organizations, those organizations\n",
      "are often either reluctant to invest or unable to achieve the returns they aspire to. This article\n",
      "systematically explores the barriers LSCM organizations experience in employing supply chain\n",
      "analytics that contribute to such reluctance and unachieved returns and measures to overcome these\n",
      "barriers. This article therefore aims to systemize the barriers and measures and allocate measures to\n",
      "barriers in order to provide or\n"
     ]
    }
   ],
   "source": [
    "print(papers[19][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#Performing tokenizaation, lemmatization, stemming and removing stop words\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def normalize_corpus(papers):\n",
    "    norm_papers = []\n",
    "    for paper in papers:\n",
    "        paper = paper.lower()\n",
    "        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]\n",
    "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
    "        paper_tokens = [token for token in paper_tokens if len(token) > 1]\n",
    "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
    "        paper_tokens = list(filter(None, paper_tokens))\n",
    "        if paper_tokens:\n",
    "            norm_papers.append(paper_tokens)\n",
    "            \n",
    "    return norm_papers\n",
    "    \n",
    "norm_papers = normalize_corpus(papers)\n",
    "print(len(norm_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agriculture', 'article', 'influence', 'specie', 'composition', 'management', 'biomass', 'production', 'missouri', 'ranjith', 'udawatta', 'clark', 'gantzer', 'timothy', 'reinbott', 'ray', 'wright', 'robert', 'pierce', 'ii', 'walter', 'wehtje', 'school', 'natural', 'resource', 'university', 'missouri', 'columbia', 'mo', 'usa', 'gantzerc', 'missouri', 'edu', 'piercer', 'missouri', 'edu', 'ii', 'wehtjew', 'missouri', 'edu', 'center', 'agroforestry', 'school', 'natural', 'resource', 'university', 'missouri', 'columbia', 'mo', 'usa']\n"
     ]
    }
   ],
   "source": [
    "print(norm_papers[0][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3)  Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5479)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting a collection of text documents to a matrix of token counts\n",
    "\n",
    "cv = CountVectorizer(min_df=0.1, max_df=0.7, ngram_range=(1,2),\n",
    "                     token_pattern=None, tokenizer=lambda doc: doc,\n",
    "                     preprocessor=lambda doc: doc)\n",
    "cv_features = cv.fit_transform(norm_papers)\n",
    "cv_features.shape                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 5479\n"
     ]
    }
   ],
   "source": [
    "vocabulary = np.array(cv.get_feature_names())\n",
    "print('Total Vocabulary Size:', len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Topic modeling with Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "TOTAL_TOPICS = 20\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components =TOTAL_TOPICS, max_iter=500, max_doc_update_iter=50,\n",
    "                                      learning_method='online', batch_size=5479, learning_offset=50., \n",
    "                                      random_state=42, n_jobs=16)\n",
    "document_topics = lda_model.fit_transform(cv_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_terms = lda_model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Terms per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58f07437a454f23b2045ae878c04302"
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms per Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Topic1</td>\n",
       "      <td>energy, pig, growing, diet, content, fed, fiber, nutrient, adult, greater, animal, ge, corn, dm, acid, crossref, protein, meal, matter, stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic2</td>\n",
       "      <td>inverter, output, group, apple, crossref, management, cost, power, welfare, animal, feature, wild, transport, current, october, sd, approach, controlled, error, measure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic3</td>\n",
       "      <td>analytics, measure, barrier, organization, blockchain, technical, chain, solution, fruit, supply, supply chain, business, efficiency, technical efficiency, initiative, smart, user, management, video, need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic4</td>\n",
       "      <td>proposed, error, accuracy, power, input, energy, part, carry, output, design, th, performance, scheme, reduction, operation, electronics, measure, prediction, ieee, analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic5</td>\n",
       "      <td>blockchain, group, crossref, cost, animal, score, smart, measure, higher, prediction, efficiency, density, feature, day, apple, treatment, application, analytics, ieee, approach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic6</td>\n",
       "      <td>image, bc, focus, group, fusion, crossref, proposed, treatment, mouse, image fusion, technique, region, map, il, animal, expression, score, intestinal, administration, multi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic7</td>\n",
       "      <td>output, power, design, voltage, current, electronics, core, density, proposed, equation, simulation, input, efficiency, frequency, ieee, loss, dc, energy, equivalent, circuit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic8</td>\n",
       "      <td>energy, cost, broiler, density, area, inverter, feature, crossref, animal, current, management, frequency, controlled, score, output, power, bird, production, distance, voltage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic9</td>\n",
       "      <td>analytics, yield, energy, blockchain, barrier, crossref, feature, measure, management, approach, treatment, growing, solution, pig, prediction, organization, algorithm, biomass, efficiency, technical efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic10</td>\n",
       "      <td>wild, west, italy, sample, antibody, crossref, positive, serum, animal, european, presence, region, adult, mammal, dis, dis crossref, surveillance, human, pcr, bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic11</td>\n",
       "      <td>management, inverter, efficiency, energy, output, crossref, current, yield, group, controlled, technical, bc, farmer, technical efficiency, maize, score, transport, two three, like, signal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic12</td>\n",
       "      <td>inverter, controlled, transport, feature, apple, prediction, cost, welfare, score, crossref, group, criterion, logistics, preharvest, error, terminal, broiler, port, distance, experiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic13</td>\n",
       "      <td>analytics, logistics, image, technical, business, criterion, application, allows, efficiency, chem crossref, initiative, gene, mean sd, chain, identified, sorting, driver, last, study concludes, chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic14</td>\n",
       "      <td>energy, production, crossref, welfare, cost, management, score, treatment, efficiency, economic, animal, group, s1, input, sci crossref, test, fruit, sd, maize, average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic15</td>\n",
       "      <td>analytics, measure, barrier, crossref, supply chain, supply, blockchain, image, need, approach, proposed, organization, group, score, logistics, day, chain, energy, section, business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic16</td>\n",
       "      <td>chicken, gene, ax, color, wide, animal, plumage, genetic, association, marker, population, local, region, white, trait, candidate, anim, pb, involved, genomic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic17</td>\n",
       "      <td>inverter, loop, current, crossref, new, power, advance, output, diagram, equation, change, image, technical, ieee, colón, proposed, controlled, electronics, efficiency, period</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic18</td>\n",
       "      <td>yield, management, energy, production, biomass, maize, harvest, year, efficiency, agriculture, crop, cutting, crossref, soil, height, cm, mixture, ii, input, mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic19</td>\n",
       "      <td>crossref, yield, biomass, group, treatment, fruit, preharvest, criterion, inverter, treated, harvest, lower, cost, smart, apple, cutting, blockchain, animal, day, specie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic20</td>\n",
       "      <td>welfare, score, cost, production, broiler, analytics, animal, measure, profit, nc, china, management, crossref, economic, per, total cost, transport, group, higher, biomass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                            Terms per Topic\n",
       "Topic1   energy, pig, growing, diet, content, fed, fiber, nutrient, adult, greater, animal, ge, corn, dm, acid, crossref, protein, meal, matter, stage                                                                     \n",
       "Topic2   inverter, output, group, apple, crossref, management, cost, power, welfare, animal, feature, wild, transport, current, october, sd, approach, controlled, error, measure                                          \n",
       "Topic3   analytics, measure, barrier, organization, blockchain, technical, chain, solution, fruit, supply, supply chain, business, efficiency, technical efficiency, initiative, smart, user, management, video, need      \n",
       "Topic4   proposed, error, accuracy, power, input, energy, part, carry, output, design, th, performance, scheme, reduction, operation, electronics, measure, prediction, ieee, analytics                                    \n",
       "Topic5   blockchain, group, crossref, cost, animal, score, smart, measure, higher, prediction, efficiency, density, feature, day, apple, treatment, application, analytics, ieee, approach                                 \n",
       "Topic6   image, bc, focus, group, fusion, crossref, proposed, treatment, mouse, image fusion, technique, region, map, il, animal, expression, score, intestinal, administration, multi                                     \n",
       "Topic7   output, power, design, voltage, current, electronics, core, density, proposed, equation, simulation, input, efficiency, frequency, ieee, loss, dc, energy, equivalent, circuit                                    \n",
       "Topic8   energy, cost, broiler, density, area, inverter, feature, crossref, animal, current, management, frequency, controlled, score, output, power, bird, production, distance, voltage                                  \n",
       "Topic9   analytics, yield, energy, blockchain, barrier, crossref, feature, measure, management, approach, treatment, growing, solution, pig, prediction, organization, algorithm, biomass, efficiency, technical efficiency\n",
       "Topic10  wild, west, italy, sample, antibody, crossref, positive, serum, animal, european, presence, region, adult, mammal, dis, dis crossref, surveillance, human, pcr, bird                                              \n",
       "Topic11  management, inverter, efficiency, energy, output, crossref, current, yield, group, controlled, technical, bc, farmer, technical efficiency, maize, score, transport, two three, like, signal                      \n",
       "Topic12  inverter, controlled, transport, feature, apple, prediction, cost, welfare, score, crossref, group, criterion, logistics, preharvest, error, terminal, broiler, port, distance, experiment                        \n",
       "Topic13  analytics, logistics, image, technical, business, criterion, application, allows, efficiency, chem crossref, initiative, gene, mean sd, chain, identified, sorting, driver, last, study concludes, chicken        \n",
       "Topic14  energy, production, crossref, welfare, cost, management, score, treatment, efficiency, economic, animal, group, s1, input, sci crossref, test, fruit, sd, maize, average                                          \n",
       "Topic15  analytics, measure, barrier, crossref, supply chain, supply, blockchain, image, need, approach, proposed, organization, group, score, logistics, day, chain, energy, section, business                            \n",
       "Topic16  chicken, gene, ax, color, wide, animal, plumage, genetic, association, marker, population, local, region, white, trait, candidate, anim, pb, involved, genomic                                                    \n",
       "Topic17  inverter, loop, current, crossref, new, power, advance, output, diagram, equation, change, image, technical, ieee, colón, proposed, controlled, electronics, efficiency, period                                   \n",
       "Topic18  yield, management, energy, production, biomass, maize, harvest, year, efficiency, agriculture, crop, cutting, crossref, soil, height, cm, mixture, ii, input, mg                                                  \n",
       "Topic19  crossref, yield, biomass, group, treatment, fruit, preharvest, criterion, inverter, treated, harvest, lower, cost, smart, apple, cutting, blockchain, animal, day, specie                                         \n",
       "Topic20  welfare, score, cost, production, broiler, analytics, animal, measure, profit, nc, china, management, crossref, economic, per, total cost, transport, group, higher, biomass                                      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Keywords for the various topics\n",
    "top_terms = 20\n",
    "topic_key_term_idxs = np.argsort(-np.absolute(topic_terms), axis=1)[:, :top_terms]\n",
    "topic_keyterms = vocabulary[topic_key_term_idxs]\n",
    "topics = [', '.join(topic) for topic in topic_keyterms]\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df = pd.DataFrame(topics,\n",
    "                         columns = ['Terms per Topic'],\n",
    "                         index=['Topic'+str(t) for t in range(1, TOTAL_TOPICS+1)])\n",
    "topics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Weight of each terms in a particular topic with respect to each document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e8bd6fae1d48c9ac77cc73aa8634ab"
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>T1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.10140</td>\n",
       "      <td>0.03856</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.99971</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T2</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T3</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.76056</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.79294</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.94582</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.31728</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.99987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T4</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T5</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T6</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.02702</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.99971</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.07782</td>\n",
       "      <td>0.99962</td>\n",
       "      <td>0.02612</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T7</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.33265</td>\n",
       "      <td>0.99958</td>\n",
       "      <td>0.23881</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.02781</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T8</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T9</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T10</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.99948</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T11</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T12</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.96121</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.02589</td>\n",
       "      <td>0.89600</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.66710</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.68303</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.99985</td>\n",
       "      <td>0.91166</td>\n",
       "      <td>0.63775</td>\n",
       "      <td>0.97240</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T13</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T14</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T15</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T16</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00750</td>\n",
       "      <td>0.03590</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.99943</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.07695</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T17</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T18</td>\n",
       "      <td>0.99973</td>\n",
       "      <td>0.23916</td>\n",
       "      <td>0.03853</td>\n",
       "      <td>0.99971</td>\n",
       "      <td>0.04500</td>\n",
       "      <td>0.02931</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.04460</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T19</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>T20</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1       2       3       4       5       6       7       8  \\\n",
       "T1  0.00001 0.00002 0.00001 0.00002 0.10140 0.03856 0.00002 0.00003 0.00003   \n",
       "T2  0.00001 0.00002 0.00001 0.00002 0.00002 0.00001 0.00002 0.00003 0.00003   \n",
       "T3  0.00001 0.76056 0.00001 0.00002 0.79294 0.00001 0.00002 0.00003 0.00003   \n",
       "T4  0.00001 0.00002 0.00001 0.00002 0.00002 0.00001 0.00002 0.00003 0.00003   \n",
       "T5  0.00001 0.00002 0.00001 0.00002 0.00002 0.00001 0.00002 0.00003 0.00003   \n",
       "T6  0.00001 0.00002 0.00001 0.00002 0.02702 0.00001 0.99971 0.00003 0.00003   \n",
       "T7  0.00001 0.00002 0.00001 0.00002 0.00002 0.00001 0.00002 0.00003 0.00003   \n",
       "T8  0.00001 0.00002 0.00001 0.00002 0.00002 0.00001 0.00002 0.00003 0.00003   \n",
       "T9  0.00001 0.00002 0.00001 0.00002 0.00002 0.00001 0.00002 0.00003 0.00003   \n",
       "T10 0.00001 0.00002 0.00001 0.00002 0.00002 0.00001 0.00002 0.00003 0.99948   \n",
       "T11 0.00001 0.00002 0.00001 0.00002 0.00002 0.00001 0.00002 0.00003 0.00003   \n",
       "T12 0.00001 0.00002 0.96121 0.00002 0.02589 0.89600 0.00002 0.00003 0.00003   \n",
       "T13 0.00001 0.00002 0.00001 0.00002 0.00002 0.00001 0.00002 0.00003 0.00003   \n",
       "T14 0.00001 0.00002 0.00001 0.00002 0.00002 0.00001 0.00002 0.00003 0.00003   \n",
       "T15 0.00001 0.00002 0.00001 0.00002 0.00002 0.00001 0.00002 0.00003 0.00003   \n",
       "T16 0.00001 0.00002 0.00001 0.00002 0.00750 0.03590 0.00002 0.99943 0.00003   \n",
       "T17 0.00001 0.00002 0.00001 0.00002 0.00002 0.00001 0.00002 0.00003 0.00003   \n",
       "T18 0.99973 0.23916 0.03853 0.99971 0.04500 0.02931 0.00002 0.00003 0.00003   \n",
       "T19 0.00001 0.00002 0.00001 0.00002 0.00002 0.00001 0.00002 0.00003 0.00003   \n",
       "T20 0.00001 0.00002 0.00001 0.00002 0.00002 0.00001 0.00002 0.00003 0.00003   \n",
       "\n",
       "          9      10      11      12      13      14      15      16      17  \\\n",
       "T1  0.99971 0.00001 0.00002 0.00002 0.00002 0.00001 0.00001 0.00063 0.00002   \n",
       "T2  0.00002 0.00001 0.00002 0.00002 0.00002 0.00001 0.00001 0.00063 0.00002   \n",
       "T3  0.00002 0.00001 0.00002 0.00002 0.00002 0.94582 0.00001 0.00063 0.31728   \n",
       "T4  0.00002 0.00001 0.00002 0.00002 0.00002 0.00001 0.00001 0.00063 0.00002   \n",
       "T5  0.00002 0.00001 0.00002 0.00002 0.00002 0.00001 0.00001 0.00063 0.00002   \n",
       "T6  0.00002 0.00001 0.00002 0.07782 0.99962 0.02612 0.00001 0.00063 0.00002   \n",
       "T7  0.00002 0.33265 0.99958 0.23881 0.00002 0.02781 0.00001 0.00063 0.00002   \n",
       "T8  0.00002 0.00001 0.00002 0.00002 0.00002 0.00001 0.00001 0.00063 0.00002   \n",
       "T9  0.00002 0.00001 0.00002 0.00002 0.00002 0.00001 0.00001 0.00063 0.00002   \n",
       "T10 0.00002 0.00001 0.00002 0.00002 0.00002 0.00001 0.00001 0.00063 0.00002   \n",
       "T11 0.00002 0.00001 0.00002 0.00002 0.00002 0.00001 0.00001 0.00063 0.00002   \n",
       "T12 0.00002 0.66710 0.00002 0.68303 0.00002 0.00001 0.99985 0.91166 0.63775   \n",
       "T13 0.00002 0.00001 0.00002 0.00002 0.00002 0.00001 0.00001 0.00063 0.00002   \n",
       "T14 0.00002 0.00001 0.00002 0.00002 0.00002 0.00001 0.00001 0.00063 0.00002   \n",
       "T15 0.00002 0.00001 0.00002 0.00002 0.00002 0.00001 0.00001 0.00063 0.00002   \n",
       "T16 0.00002 0.00001 0.00002 0.00002 0.00002 0.00001 0.00001 0.07695 0.00002   \n",
       "T17 0.00002 0.00001 0.00002 0.00002 0.00002 0.00001 0.00001 0.00063 0.00002   \n",
       "T18 0.00002 0.00001 0.00002 0.00002 0.00002 0.00001 0.00001 0.00063 0.04460   \n",
       "T19 0.00002 0.00001 0.00002 0.00002 0.00002 0.00001 0.00001 0.00063 0.00002   \n",
       "T20 0.00002 0.00001 0.00002 0.00002 0.00002 0.00001 0.00001 0.00063 0.00002   \n",
       "\n",
       "         18      19  \n",
       "T1  0.00002 0.00001  \n",
       "T2  0.00002 0.00001  \n",
       "T3  0.02729 0.99987  \n",
       "T4  0.00002 0.00001  \n",
       "T5  0.00002 0.00001  \n",
       "T6  0.00002 0.00001  \n",
       "T7  0.00002 0.00001  \n",
       "T8  0.00002 0.00001  \n",
       "T9  0.00002 0.00001  \n",
       "T10 0.00002 0.00001  \n",
       "T11 0.00002 0.00001  \n",
       "T12 0.97240 0.00001  \n",
       "T13 0.00002 0.00001  \n",
       "T14 0.00002 0.00001  \n",
       "T15 0.00002 0.00001  \n",
       "T16 0.00002 0.00001  \n",
       "T17 0.00002 0.00001  \n",
       "T18 0.00002 0.00001  \n",
       "T19 0.00002 0.00001  \n",
       "T20 0.00002 0.00001  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "dt_df = pd.DataFrame(document_topics, \n",
    "                     columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "dt_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7)  Dominant topic for each research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef2386254d944099a4f4cc272730642"
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th>Contribution %</th>\n",
       "      <th>Paper Num</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Paper Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Topic1</td>\n",
       "      <td>T1</td>\n",
       "      <td>0.99971</td>\n",
       "      <td>9</td>\n",
       "      <td>energy, pig, growing, diet, content, fed, fiber, nutrient, adult, greater, animal, ge, corn, dm, acid, crossref, protein, meal, matter, stage</td>\n",
       "      <td>animals\\nArticle\\n\\nEffects of Different Crude Protein and Dietary Fiber\\nLevels on the Comparative Energy and Nutrient\\nUtilization in Sows and Growing Pigs\\nWenxuan Dong, Gang Zhang, Zhongchao L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic2</td>\n",
       "      <td>T2</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>16</td>\n",
       "      <td>inverter, output, group, apple, crossref, management, cost, power, welfare, animal, feature, wild, transport, current, october, sd, approach, controlled, error, measure</td>\n",
       "      <td>Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic3</td>\n",
       "      <td>T3</td>\n",
       "      <td>0.99987</td>\n",
       "      <td>19</td>\n",
       "      <td>analytics, measure, barrier, organization, blockchain, technical, chain, solution, fruit, supply, supply chain, business, efficiency, technical efficiency, initiative, smart, user, management, vid...</td>\n",
       "      <td>Article\\n\\nOvercoming Barriers in Supply Chain Analytics—\\nInvestigating Measures in LSCM Organizations\\nTino T. Herden *, Benjamin Nitsche and Benno Gerlach\\nChair of Logistics, Technische Univer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic4</td>\n",
       "      <td>T4</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>16</td>\n",
       "      <td>proposed, error, accuracy, power, input, energy, part, carry, output, design, th, performance, scheme, reduction, operation, electronics, measure, prediction, ieee, analytics</td>\n",
       "      <td>Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic5</td>\n",
       "      <td>T5</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>16</td>\n",
       "      <td>blockchain, group, crossref, cost, animal, score, smart, measure, higher, prediction, efficiency, density, feature, day, apple, treatment, application, analytics, ieee, approach</td>\n",
       "      <td>Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic6</td>\n",
       "      <td>T6</td>\n",
       "      <td>0.99971</td>\n",
       "      <td>6</td>\n",
       "      <td>image, bc, focus, group, fusion, crossref, proposed, treatment, mouse, image fusion, technique, region, map, il, animal, expression, score, intestinal, administration, multi</td>\n",
       "      <td>animals\\nArticle\\n\\nThe Prophylactic Use of Bovine Colostrum in a\\nMurine Model of TNBS-Induced Colitis\\nLaura Menchetti 1 , Giulio Curone 2 , Iulia Elena Filipescu 3 , Olimpia Barbato 1 ,\\nLeonar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic7</td>\n",
       "      <td>T7</td>\n",
       "      <td>0.99958</td>\n",
       "      <td>11</td>\n",
       "      <td>output, power, design, voltage, current, electronics, core, density, proposed, equation, simulation, input, efficiency, frequency, ieee, loss, dc, energy, equivalent, circuit</td>\n",
       "      <td>Article\\n\\nPower Density Maximization in Medium Frequency\\nTransformers by Using Their Maximum Flux Density\\nfor DC–DC Converters\\nDante Ruiz-Robles 1,*, Edgar L. Moreno-Goytia 1, Vicente Venegas-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic8</td>\n",
       "      <td>T8</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>16</td>\n",
       "      <td>energy, cost, broiler, density, area, inverter, feature, crossref, animal, current, management, frequency, controlled, score, output, power, bird, production, distance, voltage</td>\n",
       "      <td>Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic9</td>\n",
       "      <td>T9</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>16</td>\n",
       "      <td>analytics, yield, energy, blockchain, barrier, crossref, feature, measure, management, approach, treatment, growing, solution, pig, prediction, organization, algorithm, biomass, efficiency, techni...</td>\n",
       "      <td>Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic10</td>\n",
       "      <td>T10</td>\n",
       "      <td>0.99948</td>\n",
       "      <td>8</td>\n",
       "      <td>wild, west, italy, sample, antibody, crossref, positive, serum, animal, european, presence, region, adult, mammal, dis, dis crossref, surveillance, human, pcr, bird</td>\n",
       "      <td>animals\\nArticle\\n\\nWest Nile Virus and Related Flavivirus in European\\nWild Boar (Sus scrofa), Latium Region, Italy: A\\nRetrospective Study\\nAngela Petruccelli 1 , Tiziana Zottola 2 , Gianmarco F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic11</td>\n",
       "      <td>T11</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>16</td>\n",
       "      <td>management, inverter, efficiency, energy, output, crossref, current, yield, group, controlled, technical, bc, farmer, technical efficiency, maize, score, transport, two three, like, signal</td>\n",
       "      <td>Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic12</td>\n",
       "      <td>T12</td>\n",
       "      <td>0.99985</td>\n",
       "      <td>15</td>\n",
       "      <td>inverter, controlled, transport, feature, apple, prediction, cost, welfare, score, crossref, group, criterion, logistics, preharvest, error, terminal, broiler, port, distance, experiment</td>\n",
       "      <td>logistics\\nArticle\\n\\nTravel Time Prediction in a Multimodal Freight\\nTransport Relation Using Machine\\nLearning Algorithms\\nNikolaos Servos 1, *, Xiaodi Liu 1 , Michael Teucke 2 and Michael Freit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic13</td>\n",
       "      <td>T13</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>16</td>\n",
       "      <td>analytics, logistics, image, technical, business, criterion, application, allows, efficiency, chem crossref, initiative, gene, mean sd, chain, identified, sorting, driver, last, study concludes, c...</td>\n",
       "      <td>Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic14</td>\n",
       "      <td>T14</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>16</td>\n",
       "      <td>energy, production, crossref, welfare, cost, management, score, treatment, efficiency, economic, animal, group, s1, input, sci crossref, test, fruit, sd, maize, average</td>\n",
       "      <td>Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic15</td>\n",
       "      <td>T15</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>16</td>\n",
       "      <td>analytics, measure, barrier, crossref, supply chain, supply, blockchain, image, need, approach, proposed, organization, group, score, logistics, day, chain, energy, section, business</td>\n",
       "      <td>Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic16</td>\n",
       "      <td>T16</td>\n",
       "      <td>0.99943</td>\n",
       "      <td>7</td>\n",
       "      <td>chicken, gene, ax, color, wide, animal, plumage, genetic, association, marker, population, local, region, white, trait, candidate, anim, pb, involved, genomic</td>\n",
       "      <td>Article\\n\\nGenome-wide Analyses Identifies Known and New\\nMarkers Responsible of Chicken Plumage Color\\nSalvatore Mastrangelo 1, Filippo Cendron 2,*, Gianluca Sottile 3, Giovanni Niero 2,\\nBaldass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic17</td>\n",
       "      <td>T17</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>16</td>\n",
       "      <td>inverter, loop, current, crossref, new, power, advance, output, diagram, equation, change, image, technical, ieee, colón, proposed, controlled, electronics, efficiency, period</td>\n",
       "      <td>Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic18</td>\n",
       "      <td>T18</td>\n",
       "      <td>0.99973</td>\n",
       "      <td>0</td>\n",
       "      <td>yield, management, energy, production, biomass, maize, harvest, year, efficiency, agriculture, crop, cutting, crossref, soil, height, cm, mixture, ii, input, mg</td>\n",
       "      <td>agriculture\\nArticle\\n\\nInfluence of Species Composition and Management\\non Biomass Production in Missouri\\nRanjith P. Udawatta 1,2, *, Clark J. Gantzer 1 , Timothy M. Reinbott 3 , Ray L. Wright 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic19</td>\n",
       "      <td>T19</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>16</td>\n",
       "      <td>crossref, yield, biomass, group, treatment, fruit, preharvest, criterion, inverter, treated, harvest, lower, cost, smart, apple, cutting, blockchain, animal, day, specie</td>\n",
       "      <td>Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic20</td>\n",
       "      <td>T20</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>16</td>\n",
       "      <td>welfare, score, cost, production, broiler, analytics, animal, measure, profit, nc, china, management, crossref, economic, per, total cost, transport, group, higher, biomass</td>\n",
       "      <td>Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant Topic  Contribution %  Paper Num  \\\n",
       "Topic1              T1         0.99971          9   \n",
       "Topic2              T2         0.00063         16   \n",
       "Topic3              T3         0.99987         19   \n",
       "Topic4              T4         0.00063         16   \n",
       "Topic5              T5         0.00063         16   \n",
       "Topic6              T6         0.99971          6   \n",
       "Topic7              T7         0.99958         11   \n",
       "Topic8              T8         0.00063         16   \n",
       "Topic9              T9         0.00063         16   \n",
       "Topic10            T10         0.99948          8   \n",
       "Topic11            T11         0.00063         16   \n",
       "Topic12            T12         0.99985         15   \n",
       "Topic13            T13         0.00063         16   \n",
       "Topic14            T14         0.00063         16   \n",
       "Topic15            T15         0.00063         16   \n",
       "Topic16            T16         0.99943          7   \n",
       "Topic17            T17         0.00063         16   \n",
       "Topic18            T18         0.99973          0   \n",
       "Topic19            T19         0.00063         16   \n",
       "Topic20            T20         0.00063         16   \n",
       "\n",
       "                                                                                                                                                                                                           Topic  \\\n",
       "Topic1                                                             energy, pig, growing, diet, content, fed, fiber, nutrient, adult, greater, animal, ge, corn, dm, acid, crossref, protein, meal, matter, stage   \n",
       "Topic2                                  inverter, output, group, apple, crossref, management, cost, power, welfare, animal, feature, wild, transport, current, october, sd, approach, controlled, error, measure   \n",
       "Topic3   analytics, measure, barrier, organization, blockchain, technical, chain, solution, fruit, supply, supply chain, business, efficiency, technical efficiency, initiative, smart, user, management, vid...   \n",
       "Topic4                            proposed, error, accuracy, power, input, energy, part, carry, output, design, th, performance, scheme, reduction, operation, electronics, measure, prediction, ieee, analytics   \n",
       "Topic5                         blockchain, group, crossref, cost, animal, score, smart, measure, higher, prediction, efficiency, density, feature, day, apple, treatment, application, analytics, ieee, approach   \n",
       "Topic6                             image, bc, focus, group, fusion, crossref, proposed, treatment, mouse, image fusion, technique, region, map, il, animal, expression, score, intestinal, administration, multi   \n",
       "Topic7                            output, power, design, voltage, current, electronics, core, density, proposed, equation, simulation, input, efficiency, frequency, ieee, loss, dc, energy, equivalent, circuit   \n",
       "Topic8                          energy, cost, broiler, density, area, inverter, feature, crossref, animal, current, management, frequency, controlled, score, output, power, bird, production, distance, voltage   \n",
       "Topic9   analytics, yield, energy, blockchain, barrier, crossref, feature, measure, management, approach, treatment, growing, solution, pig, prediction, organization, algorithm, biomass, efficiency, techni...   \n",
       "Topic10                                     wild, west, italy, sample, antibody, crossref, positive, serum, animal, european, presence, region, adult, mammal, dis, dis crossref, surveillance, human, pcr, bird   \n",
       "Topic11             management, inverter, efficiency, energy, output, crossref, current, yield, group, controlled, technical, bc, farmer, technical efficiency, maize, score, transport, two three, like, signal   \n",
       "Topic12               inverter, controlled, transport, feature, apple, prediction, cost, welfare, score, crossref, group, criterion, logistics, preharvest, error, terminal, broiler, port, distance, experiment   \n",
       "Topic13  analytics, logistics, image, technical, business, criterion, application, allows, efficiency, chem crossref, initiative, gene, mean sd, chain, identified, sorting, driver, last, study concludes, c...   \n",
       "Topic14                                 energy, production, crossref, welfare, cost, management, score, treatment, efficiency, economic, animal, group, s1, input, sci crossref, test, fruit, sd, maize, average   \n",
       "Topic15                   analytics, measure, barrier, crossref, supply chain, supply, blockchain, image, need, approach, proposed, organization, group, score, logistics, day, chain, energy, section, business   \n",
       "Topic16                                           chicken, gene, ax, color, wide, animal, plumage, genetic, association, marker, population, local, region, white, trait, candidate, anim, pb, involved, genomic   \n",
       "Topic17                          inverter, loop, current, crossref, new, power, advance, output, diagram, equation, change, image, technical, ieee, colón, proposed, controlled, electronics, efficiency, period   \n",
       "Topic18                                         yield, management, energy, production, biomass, maize, harvest, year, efficiency, agriculture, crop, cutting, crossref, soil, height, cm, mixture, ii, input, mg   \n",
       "Topic19                                crossref, yield, biomass, group, treatment, fruit, preharvest, criterion, inverter, treated, harvest, lower, cost, smart, apple, cutting, blockchain, animal, day, specie   \n",
       "Topic20                             welfare, score, cost, production, broiler, analytics, animal, measure, profit, nc, china, management, crossref, economic, per, total cost, transport, group, higher, biomass   \n",
       "\n",
       "                                                                                                                                                                                                      Paper Name  \n",
       "Topic1   animals\\nArticle\\n\\nEffects of Different Crude Protein and Dietary Fiber\\nLevels on the Comparative Energy and Nutrient\\nUtilization in Sows and Growing Pigs\\nWenxuan Dong, Gang Zhang, Zhongchao L...  \n",
       "Topic2   Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...  \n",
       "Topic3   Article\\n\\nOvercoming Barriers in Supply Chain Analytics—\\nInvestigating Measures in LSCM Organizations\\nTino T. Herden *, Benjamin Nitsche and Benno Gerlach\\nChair of Logistics, Technische Univer...  \n",
       "Topic4   Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...  \n",
       "Topic5   Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...  \n",
       "Topic6   animals\\nArticle\\n\\nThe Prophylactic Use of Bovine Colostrum in a\\nMurine Model of TNBS-Induced Colitis\\nLaura Menchetti 1 , Giulio Curone 2 , Iulia Elena Filipescu 3 , Olimpia Barbato 1 ,\\nLeonar...  \n",
       "Topic7   Article\\n\\nPower Density Maximization in Medium Frequency\\nTransformers by Using Their Maximum Flux Density\\nfor DC–DC Converters\\nDante Ruiz-Robles 1,*, Edgar L. Moreno-Goytia 1, Vicente Venegas-...  \n",
       "Topic8   Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...  \n",
       "Topic9   Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...  \n",
       "Topic10  animals\\nArticle\\n\\nWest Nile Virus and Related Flavivirus in European\\nWild Boar (Sus scrofa), Latium Region, Italy: A\\nRetrospective Study\\nAngela Petruccelli 1 , Tiziana Zottola 2 , Gianmarco F...  \n",
       "Topic11  Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...  \n",
       "Topic12  logistics\\nArticle\\n\\nTravel Time Prediction in a Multimodal Freight\\nTransport Relation Using Machine\\nLearning Algorithms\\nNikolaos Servos 1, *, Xiaodi Liu 1 , Michael Teucke 2 and Michael Freit...  \n",
       "Topic13  Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...  \n",
       "Topic14  Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...  \n",
       "Topic15  Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...  \n",
       "Topic16  Article\\n\\nGenome-wide Analyses Identifies Known and New\\nMarkers Responsible of Chicken Plumage Color\\nSalvatore Mastrangelo 1, Filippo Cendron 2,*, Gianluca Sottile 3, Giovanni Niero 2,\\nBaldass...  \n",
       "Topic17  Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...  \n",
       "Topic18  agriculture\\nArticle\\n\\nInfluence of Species Composition and Management\\non Biomass Production in Missouri\\nRanjith P. Udawatta 1,2, *, Clark J. Gantzer 1 , Timothy M. Reinbott 3 , Ray L. Wright 3...  \n",
       "Topic19  Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...  \n",
       "Topic20  Editorial\\n\\nAcknowledgement to Reviewers of Logistics in 2019\\nLogistics Editorial Office\\nMDPI, St. Alban-Anlage 66, 4052 Basel, Switzerland\\nPublished: 30 January 2020\\n\\nThe editorial team gre...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "max_contrib_topics = dt_df.max(axis=0)\n",
    "dominant_topics = max_contrib_topics.index\n",
    "contrib_perc = max_contrib_topics.values\n",
    "document_numbers = [dt_df[dt_df[t] == max_contrib_topics.loc[t]].index[0]\n",
    "                       for t in dominant_topics]\n",
    "documents = [papers[i] for i in document_numbers]\n",
    "\n",
    "results_df = pd.DataFrame({'Dominant Topic': dominant_topics, 'Contribution %': contrib_perc,\n",
    "                          'Paper Num': document_numbers, 'Topic': topics_df['Terms per Topic'], \n",
    "                          'Paper Name': documents})\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Predicting Topics for New Research Papers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Documents: 1\n"
     ]
    }
   ],
   "source": [
    "new_paper_files = glob.glob('test_txt.txt')\n",
    "new_papers = []\n",
    "for fn in new_paper_files:\n",
    "    with open(fn, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
    "        data = f.read()\n",
    "        new_papers.append(data)\n",
    "              \n",
    "print('Total Documents:', len(new_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5479)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_new_papers = normalize_corpus(new_papers)\n",
    "cv_new_features = cv.transform(norm_new_papers)\n",
    "cv_new_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['article', 'financial', 'spillover', 'effect', 'supply', 'chain', 'customer', 'supplier', 'really', 'benefit', 'erik', 'hofmann', 'yannick', 'sertori', 'institute', 'supply', 'chain', 'management', 'university', 'st', 'gallen', 'st', 'gallen', 'switzerland', 'correspondence', 'erik', 'hofmann', 'unisg', 'ch', 'received', 'february', 'accepted', 'march', 'published', 'march', 'abstract', 'study', 'shown', 'leading', 'supply', 'chain', 'company', 'associated', 'significantly', 'higher', 'company', 'financial', 'ratio', 'competitor', 'contrast', 'little', 'research', 'ha', 'focused', 'financial', 'performance', 'affiliated', 'supplier', 'customer', 'supply', 'chain', 'leader', 'scl', 'company', 'thus', 'central', 'purpose', 'paper', 'determine', 'financial', 'perspective', 'whether', 'supplier', 'customer', 'benefit', 'lose', 'participating', 'scl', 'network', 'called', 'financial', 'spillover', 'effect', 'company', 'ranked', 'gartner', 'supply', 'chain', 'top', 'selected', 'scls', 'selected', 'firm', 'five', 'largest', 'supplier', 'customer', 'identified', 'compared', 'control']\n"
     ]
    }
   ],
   "source": [
    "print(norm_new_papers[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2, 0.633), (11, 0.254)]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_predictions = lda_model.transform(cv_new_features)\n",
    "best_topics = [[(topic, round(sc, 3)) \n",
    "                    for topic, sc in sorted(enumerate(topic_predictions[i]), \n",
    "                                            key=lambda row: -row[1])[:2]] \n",
    "                        for i in range(len(topic_predictions))]\n",
    "best_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3c3b47c74a414382e6a092c74a32c2"
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant Topics</th>\n",
       "      <th>Topic Score</th>\n",
       "      <th>Topic Desc</th>\n",
       "      <th>Paper Desc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Papers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>63.30000</td>\n",
       "      <td>inverter, output, group, apple, crossref, management, cost, power, welfare, animal, feature, wild, transport, current, october, sd, approach, controlled, error, measure</td>\n",
       "      <td>Article\\n\\nFinancial Spillover Effects in Supply Chains:\\nDo Customers and Suppliers Really Benefit?\\nErik Hofmann * and Yannick Sertori\\nInstitute of Supply Chain Management, University of St. Ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>25.40000</td>\n",
       "      <td>management, inverter, efficiency, energy, output, crossref, current, yield, group, controlled, technical, bc, farmer, technical efficiency, maize, score, transport, two three, like, signal</td>\n",
       "      <td>Article\\n\\nFinancial Spillover Effects in Supply Chains:\\nDo Customers and Suppliers Really Benefit?\\nErik Hofmann * and Yannick Sertori\\nInstitute of Supply Chain Management, University of St. Ga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant Topics  Topic Score  \\\n",
       "Papers                                 \n",
       "1                     2     63.30000   \n",
       "1                    11     25.40000   \n",
       "\n",
       "                                                                                                                                                                                          Topic Desc  \\\n",
       "Papers                                                                                                                                                                                                 \n",
       "1                           inverter, output, group, apple, crossref, management, cost, power, welfare, animal, feature, wild, transport, current, october, sd, approach, controlled, error, measure   \n",
       "1       management, inverter, efficiency, energy, output, crossref, current, yield, group, controlled, technical, bc, farmer, technical efficiency, maize, score, transport, two three, like, signal   \n",
       "\n",
       "                                                                                                                                                                                                     Paper Desc  \n",
       "Papers                                                                                                                                                                                                           \n",
       "1       Article\\n\\nFinancial Spillover Effects in Supply Chains:\\nDo Customers and Suppliers Really Benefit?\\nErik Hofmann * and Yannick Sertori\\nInstitute of Supply Chain Management, University of St. Ga...  \n",
       "1       Article\\n\\nFinancial Spillover Effects in Supply Chains:\\nDo Customers and Suppliers Really Benefit?\\nErik Hofmann * and Yannick Sertori\\nInstitute of Supply Chain Management, University of St. Ga...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "results_df['Papers'] = range(1, len(new_papers)+1)\n",
    "results_df['Dominant Topics'] = [[topic_num for topic_num, sc in item] for item in best_topics]\n",
    "res = results_df.set_index(['Papers'])['Dominant Topics'].apply(pd.Series).stack().reset_index(level=1, drop=True)\n",
    "results_df = pd.DataFrame({'Dominant Topics': res.values}, index=res.index)\n",
    "results_df['Topic Score'] = [topic_sc for topic_list in \n",
    "                                        [[round(sc*100, 2) \n",
    "                                              for topic_num, sc in item] \n",
    "                                                 for item in best_topics] \n",
    "                                    for topic_sc in topic_list]\n",
    "\n",
    "results_df['Topic Desc'] = [topics_df.iloc[t-1]['Terms per Topic'] for t in results_df['Dominant Topics'].values]\n",
    "results_df['Paper Desc'] = [new_papers[i-1][:200] for i in results_df.index.values]\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9) Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import dill\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('LDA_model.pkl', 'wb') as f:\n",
    "    dill.dump(lda_model, f)\n",
    "with open('cv_features.pkl', 'wb') as f:\n",
    "    dill.dump(cv_features, f)\n",
    "with open('cv.pkl', 'wb') as f:\n",
    "    dill.dump(cv, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LDA_model.pkl', 'rb') as f:\n",
    "    LDA_model = dill.load(f)\n",
    "with open('cv_features.pkl', 'rb') as f:\n",
    "    cv_features = dill.load(f)\n",
    "with open('cv.pkl', 'rb') as f:\n",
    "    cv = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(LDA_model, cv_features, cv, mds='mmds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10) Conclusion"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The trained LDA model is tested with the new research paper which is from the\n",
    "logistics domain, predict the dominant Topic No as 2 with the topics score as\n",
    "63.30 and another dominant Topic No as 11 with the topic score as 25.40.\n",
    "Topics 2 belong to research paper No 19 which is of logistics domain, Whereas\n",
    "Topics 11 belong to research paper No 15 which is of electronics domain.\n",
    "As per the prediction new research paper has highest topic score for Topic 2\n",
    "(logistic domain) which is same as our actual tested paper."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
